{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the activities done on day 3 of learning. I finished day 2 exercises and got started with a bit of day 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making your own modules (remnant from day 2)\n",
    "Not a hard section! Just an hour and 21 minutes spent on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Optional, Callable\n",
    "import torch as t\n",
    "IntOrPair = Union[int, tuple[int, int]]\n",
    "Pair = tuple[int, int]\n",
    "\n",
    "def force_pair(v: IntOrPair) -> Pair:\n",
    "    '''Convert v to a pair of int, if it isn't already.'''\n",
    "    if isinstance(v, tuple):\n",
    "        if len(v) != 2:\n",
    "            raise ValueError(v)\n",
    "        return (int(v[0]), int(v[1]))\n",
    "    elif isinstance(v, int):\n",
    "        return (v, v)\n",
    "    raise ValueError(v)\n",
    "\n",
    "def pad2d(x: t.Tensor, left: int, right: int, top: int, bottom: int, pad_value: float) -> t.Tensor:\n",
    "    '''Return a new tensor with padding applied to the edges.\n",
    "\n",
    "    x: shape (batch, in_channels, height, width), dtype float32\n",
    "\n",
    "    Return: shape (batch, in_channels, top + height + bottom, left + width + right)\n",
    "    '''\n",
    "    B, I, H, W = x.shape\n",
    "\n",
    "    tens = x.new_full((B, I, top + H + bottom, left + W + right), pad_value)\n",
    "    tens[...,top:top+H, left:left + W] = x\n",
    "    return tens\n",
    "\n",
    "\n",
    "\n",
    "# Examples of how this function can be used:\n",
    "#       force_pair((1, 2))     ->  (1, 2)\n",
    "#       force_pair(2)          ->  (2, 2)\n",
    "#       force_pair((1, 2, 3))  ->  ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually verify that this is an informative repr: MaxPool2d(kernel_size = (3, 3) stride = (2, 2) padding = (1, 1))\n"
     ]
    }
   ],
   "source": [
    "import utilsd2\n",
    "import torch.nn as nn\n",
    "\n",
    "class MaxPool2d(nn.Module):\n",
    "    def __init__(self, kernel_size: IntOrPair, stride: Optional[IntOrPair] = None, padding: IntOrPair = 1):\n",
    "        super().__init__()\n",
    "        if stride == None:\n",
    "            stride = kernel_size\n",
    "        kernel_size = force_pair(kernel_size)\n",
    "        stride = force_pair(stride)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = force_pair(padding)\n",
    "\n",
    "        \n",
    "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
    "        new_x = pad2d(x, self.padding[1], self.padding[1], self.padding[0], self.padding[0], -99999999999)\n",
    "        batch, in_channels, height, width = x.shape\n",
    "        kernel_height = self.kernel_size[0]\n",
    "        kernel_width = self.kernel_size[1]\n",
    "\n",
    "        xB, xIB, xH, xW = new_x.stride()\n",
    "\n",
    "        output_width = 1 + (width + 2 * self.padding[1] - kernel_width) // self.stride[1]\n",
    "        output_height = 1 + (height + 2 * self.padding[0] - kernel_height) // self.stride[0]\n",
    "        size = (batch, in_channels, output_height, output_width, kernel_height, kernel_width)\n",
    "        strides = (xB, xIB, xH * self.stride[0], xW * self.stride[1],  xH, xW)\n",
    "        new_x = t.as_strided(new_x, size, strides)\n",
    "\n",
    "        new_x = t.amax(new_x, 5)\n",
    "        new_x = t.amax(new_x, 4)\n",
    "        return new_x\n",
    "\n",
    "\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        '''Add additional information to the string representation of this class.'''\n",
    "        output = \"\"\n",
    "        output += \"kernel_size = \" + str(self.kernel_size)\n",
    "        output += \" stride = \" + str(self.stride)\n",
    "        output += \" padding = \" + str(self.padding)\n",
    "        return output\n",
    "        \n",
    "\n",
    "utilsd2.test_maxpool2d_module(MaxPool2d)\n",
    "m = MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "print(f\"Manually verify that this is an informative repr: {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(nn.Module):\n",
    "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
    "        return t.maximum(x, t.tensor(0.0))\n",
    "\n",
    "utilsd2.test_relu(ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatten(start_dim = 2 end_dim = 3)\n"
     ]
    }
   ],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self, start_dim: int = 1, end_dim: int = -1) -> None:\n",
    "        super().__init__()\n",
    "        self.start_dim = start_dim\n",
    "        self.end_dim = end_dim\n",
    "\n",
    "    def forward(self, input: t.Tensor) -> t.Tensor:\n",
    "        '''Flatten out dimensions from start_dim to end_dim, inclusive of both.\n",
    "        '''\n",
    "        # get start and end dimensions\n",
    "        start, end = self.start_dim, self.end_dim\n",
    "        if (start < 0):\n",
    "            start = len(input.shape) + start\n",
    "        if (end < 0):\n",
    "            end = len(input.shape) + end\n",
    "\n",
    "        # get shape of output\n",
    "        shape = []\n",
    "        for index in range(len(input.shape)):\n",
    "            shape.append(input.shape[index])\n",
    "        \n",
    "        # on start_dim element, multiply each value up until end_dim, removing them each time\n",
    "        to_remove = end - start\n",
    "        for i in range(to_remove):\n",
    "            shape[start] *= shape.pop(start + 1)\n",
    "        shape = tuple(shape)\n",
    "\n",
    "        reshaped = t.reshape(input,shape)\n",
    "        return reshaped\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        output = \"\"\n",
    "        output += \"start_dim = \" + str(self.start_dim) + \" \"\n",
    "        output += \"end_dim = \" + str(self.end_dim)\n",
    "\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "utilsd2.test_flatten(Flatten)\n",
    "f = Flatten(2,3)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(weight.shape = torch.Size([4, 3]) bias.shape = torch.Size([4]))\n"
     ]
    }
   ],
   "source": [
    "from audioop import bias\n",
    "import math\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias=True):\n",
    "        '''A simple linear (technically, affine) transformation.\n",
    "\n",
    "        The fields should be named `weight` and `bias` for compatibility with PyTorch.\n",
    "        If `bias` is False, set `self.bias` to None.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        bound = -1 / math.sqrt(in_features)\n",
    "        self.weight = nn.Parameter(t.FloatTensor(out_features,in_features).uniform_(bound, -bound))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(t.FloatTensor(out_features).uniform_(bound, -bound))\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
    "        '''\n",
    "        x: shape (*, in_features)\n",
    "        Return: shape (*, out_features)\n",
    "        '''\n",
    "        result = x@self.weight.T\n",
    "        if self.bias != None:\n",
    "            result = result + self.bias\n",
    "        return result\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        output = \"\"\n",
    "        output += \"weight.shape = \" + str(self.weight.shape) + \" \"\n",
    "        if self.bias != None:\n",
    "            output += \"bias.shape = \" + str(self.bias.shape)\n",
    "        else:\n",
    "            output += \"bias = None\"\n",
    "        return output\n",
    "\n",
    "\n",
    "utilsd2.test_linear_forward(Linear)\n",
    "utilsd2.test_linear_parameters(Linear)\n",
    "utilsd2.test_linear_no_bias(Linear)\n",
    "\n",
    "print(Linear(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(weights shape = torch.Size([3, 2, 4, 4]) stride = (1, 1) padding = (0, 0) )\n"
     ]
    }
   ],
   "source": [
    "from fancy_einsum import einsum\n",
    "class Conv2d(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels: int, out_channels: int, kernel_size: IntOrPair, stride: IntOrPair = 1, padding: IntOrPair = 0\n",
    "    ):\n",
    "        '''\n",
    "        Same as torch.nn.Conv2d with bias=False.\n",
    "\n",
    "        Name your weight field `self.weight` for compatibility with the PyTorch version.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        kernel_size = force_pair(kernel_size)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        bound = -1 / math.sqrt(kernel_size[0] * kernel_size[1] * in_channels)\n",
    "        self.weight = nn.Parameter(t.FloatTensor(out_channels, in_channels, kernel_size[0], kernel_size[1]).uniform_(bound, -bound))\n",
    "        self.stride = force_pair(stride)\n",
    "        self.padding = force_pair(padding)\n",
    "\n",
    "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
    "        # setup a strided tensor to represent input\n",
    "        new_x = pad2d(x, self.padding[1], self.padding[1], self.padding[0], self.padding[0], 0)\n",
    "        batch, in_channels, height, width = x.shape\n",
    "        out_channels, in_channels, kernel_height, kernel_width = self.weight.shape\n",
    "        xB, xIB, xH, xW = new_x.stride()\n",
    "        output_width = 1 + (width + 2 * self.padding[1] - kernel_width) // self.stride[1]\n",
    "        output_height = 1 + (height + 2 * self.padding[0] - kernel_height) // self.stride[0]\n",
    "        size = (batch, in_channels, output_height, output_width, kernel_height, kernel_width)\n",
    "        strides = (xB, xIB, xH * self.stride[0], xW * self.stride[1],  xH, xW)\n",
    "        new_x = t.as_strided(new_x, size, strides)\n",
    "\n",
    "        return einsum('batch in_channels output_height output_width kernel_height kernel_width, out_channels in_channels kernel_height kernel_width -> batch out_channels output_height output_width ', new_x, self.weight)\n",
    "\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        output = \"\"\n",
    "        output += \"weights shape = \" + str(self.weight.shape) + \" \"\n",
    "        output += \"stride = \" + str(self.stride) + \" \"\n",
    "        output += \"padding = \" + str(self.padding) + \" \"\n",
    "        return output\n",
    "\n",
    "utilsd2.test_conv2d_module(Conv2d)\n",
    "print(Conv2d(2,3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Training a CNN\n",
    "\n",
    "A lot of debugging. Fun, though. 2 hours 16 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t \n",
    "import PIL \n",
    "from PIL import Image \n",
    "import json \n",
    "from pathlib import Path \n",
    "from typing import Union, Tuple, Callable, Optional \n",
    "import plotly.graph_objects as go \n",
    "import plotly.express as px \n",
    "from plotly.subplots import make_subplots \n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the model structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(weights shape = torch.Size([32, 1, 3, 3]) stride = (1, 1) padding = (1, 1) )\n",
      "  (ReLU1): ReLU()\n",
      "  (max1): MaxPool2d(kernel_size = (2, 2) stride = (2, 2) padding = (0, 0))\n",
      "  (conv2): Conv2d(weights shape = torch.Size([64, 32, 3, 3]) stride = (1, 1) padding = (1, 1) )\n",
      "  (ReLU2): ReLU()\n",
      "  (max2): MaxPool2d(kernel_size = (2, 2) stride = (2, 2) padding = (0, 0))\n",
      "  (flatten): Flatten(start_dim = 1 end_dim = -1)\n",
      "  (lin1): Linear(weight.shape = torch.Size([128, 3136]) bias.shape = torch.Size([128]))\n",
      "  (lin2): Linear(weight.shape = torch.Size([10, 128]) bias.shape = torch.Size([10]))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(1, 32, 3, 1, 1)\n",
    "        self.ReLU1 = ReLU()\n",
    "        self.max1 = MaxPool2d(2,2,0)\n",
    "        self.conv2 = Conv2d(32, 64, 3, 1, 1)\n",
    "        self.ReLU2 = ReLU()\n",
    "        self.max2 = MaxPool2d(2,2,0)\n",
    "        self.flatten = Flatten()\n",
    "        self.lin1 = Linear(3136, 128)\n",
    "        self.lin2 = Linear(128, 10)\n",
    "\n",
    "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
    "        funcsToApply = [self.conv1, self.ReLU1, self.max1, self.conv2, self.ReLU2, self.max2, self.flatten, self.lin1, self.lin2]\n",
    "        result = x\n",
    "        for f in funcsToApply:\n",
    "            print(f)\n",
    "            result = f(x)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
    "        x = self.max1(self.ReLU1(self.conv1(x)))\n",
    "        x = self.max2(self.ReLU2(self.conv2(x)))\n",
    "        x = self.lin2(self.lin1(self.flatten(x)))\n",
    "        return x\n",
    "\n",
    "model = ConvNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision \n",
    "from torchvision import datasets, transforms \n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "trainset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief interlude on tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1eaf0ba2124a98ab8df2c132f74966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e4f5b4ec0546f6942e11771186b9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29316892db6649e6bf2b9c1039662f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1229e97ead46cfb2566e364b3b3cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f744951dd449a09d9a6d80f45f65ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76dfc5d4001417490ac06e7fcfa5b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39ddb876bca4ee8af35105f89286a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19ab977140b4f33ba2d79f485d2cd52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "import time\n",
    "\n",
    "for i in tqdm_notebook(range(100)):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "for j in tqdm_notebook(range(5)):\n",
    "    for i in tqdm_notebook(range(100), leave=False):\n",
    "        time.sleep(0.01)\n",
    "for i in tqdm_notebook(enumerate(range(100))):\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "batch_size = 128\n",
    "\n",
    "MODEL_FILENAME = \"./w1d2_convnet_mnist.pt\"\n",
    "device = \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def train_convnet(trainloader: DataLoader, epochs: int, loss_fn: Callable) -> list:\n",
    "    '''\n",
    "    Defines a ConvNet using our previous code, and trains it on the data in trainloader.\n",
    "    '''\n",
    "\n",
    "    model = ConvNet().to(device).train()\n",
    "    optimizer = t.optim.Adam(model.parameters())\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in tqdm_notebook(range(epochs)):\n",
    "\n",
    "        for (x, y) in tqdm_notebook(trainloader, leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs}, train loss is {loss:.6f}\")\n",
    "\n",
    "    print(f\"Saving model to: {MODEL_FILENAME}\")\n",
    "    t.save(model, MODEL_FILENAME)\n",
    "    return loss_list\n",
    "\n",
    "loss_list = train_convnet(trainloader, epochs, loss_fn)\n",
    "\n",
    "fig = px.line(y=loss_list, template=\"simple_white\")\n",
    "fig.update_layout(title=\"Cross entropy loss on MNIST\", yaxis_range=[0, max(loss_list)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "editeded train_convenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up training data\n",
    "\n",
    "testset = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_convnet(trainloader: DataLoader, testloader: DataLoader, epochs: int, loss_fn: Callable) -> list:\n",
    "    '''\n",
    "    Defines a ConvNet using our previous code, and trains it on the data in trainloader.\n",
    "\n",
    "    Returns tuple of (loss_list, accuracy_list), where accuracy_list contains the fraction of accurate classifications on the test set, at the end of each epoch.\n",
    "    '''\n",
    "    model = ConvNet().to(device).train()\n",
    "    optimizer = t.optim.Adam(model.parameters())\n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "\n",
    "    for epoch in tqdm_notebook(range(epochs)):\n",
    "\n",
    "        \n",
    "        for (x, y) in tqdm_notebook(trainloader, leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "            # get accuracy\n",
    "            totalCorrect = 0.0\n",
    "            count = 128\n",
    "            X_batch, y_batch = next(iter(testloader))\n",
    "            y_hat = t.argmax(model(X_batch),1)\n",
    "            totalCorrect = (y_hat == y_batch).float().sum()\n",
    "            accuracy = totalCorrect / count\n",
    "\n",
    "            print(\"totalCorrect =  \" + str(totalCorrect) + \", count = \" + str(count) )\n",
    "            print(f\"Epoch {epoch}/{epochs}, accuracy is {accuracy:.6f}\")\n",
    "            accuracy_list.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs}, train loss is {loss:.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Saving model to: {MODEL_FILENAME}\")\n",
    "    t.save(model, MODEL_FILENAME)\n",
    "    return (loss_list, accuracy_list)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "epochs = 1\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "batch_size = 128\n",
    "\n",
    "MODEL_FILENAME = \"./w1d2_convnet_mnist.pt\"\n",
    "device = \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    "\n",
    "loss_list, accuracy_list = train_convnet(trainloader, testloader, epochs, loss_fn)\n",
    "\n",
    "\n",
    "\n",
    "fig = px.line(y=loss_list, template=\"simple_white\")\n",
    "fig.update_layout(title=\"Cross entropy loss on MNIST\", yaxis_range=[0, max(loss_list)])\n",
    "fig.show()\n",
    "\n",
    "\n",
    "utils.plot_loss_and_accuracy(loss_list, accuracy_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ARENAenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1829bf021947e771a2c0399247f13cc64d76e227c4c4356073fc0c03f05b7ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
