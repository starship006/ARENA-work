{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starship006/ARENA-work/blob/main/w1/w1d4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "aOsyx41fOvuN"
      },
      "outputs": [],
      "source": [
        "import torch as t\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import fancy_einsum as einsum\n",
        "import einops\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oei89mWsOvuP"
      },
      "source": [
        "# Training Shakespeare Himself"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HguafRmOvuQ"
      },
      "source": [
        "## Copy transformer code\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9pLknZ-OvuQ"
      },
      "source": [
        "Well, not copy entirely - I'm gonna put down optimizations so it can use the GPU.\n",
        "\n",
        "And I did just that. The speed improvements are MASSIVE, wow!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SMSyuB3OvuQ",
        "outputId": "9e15be21-b4dd-48fe-cdd2-3a12249b3eac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
        "t.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "dARzlkbDOvuQ"
      },
      "outputs": [],
      "source": [
        "def multihead_masked_attention(Q: t.Tensor, K: t.Tensor, V: t.Tensor, num_heads: int):\n",
        "    '''\n",
        "    Implements multihead masked attention on the matrices Q, K and V.\n",
        "\n",
        "    Q: shape (batch, seq_len, nheads*headsize)\n",
        "    K: shape (batch, seq_len, nheads*headsize)\n",
        "    V: shape (batch, seq_len, nheads*headsize)\n",
        "    '''\n",
        "    \n",
        "    Q = einops.rearrange(Q, 'b s (n h) -> b n s h', n = num_heads)\n",
        "    K = einops.rearrange(K, 'b s (n h) -> b n s h', n = num_heads)\n",
        "    V = einops.rearrange(V, 'b s (n h) -> b n s h', n = num_heads)\n",
        "\n",
        "\n",
        "    scores = einsum.einsum('b n k h, b n s h -> b n s k', K, Q)\n",
        "    assert scores.shape == t.Size([Q.shape[0], num_heads,Q.shape[2], K.shape[2]])\n",
        "\n",
        "    scores = scores / np.sqrt(Q.shape[-1])\n",
        "    attention = scores + t.triu(t.ones_like(scores,device = device) * float(\"-inf\"), diagonal=1) # THIS IS STOLEN FROM JAY - testing it out\n",
        "    softed = t.softmax(attention,dim=-1)\n",
        "    result =  einsum.einsum('batch numheads seqQ seqK, batch numheads seqK headsize -> batch numheads seqQ headsize',softed, V)\n",
        "    return einops.rearrange(result, 'batch numheads seqQ headsize -> batch seqQ (numheads headsize)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "pxFIcpudOvuR"
      },
      "outputs": [],
      "source": [
        "class MultiheadMaskedAttention(nn.Module):\n",
        "    W_QKV: nn.Linear\n",
        "    W_O: nn.Linear\n",
        "\n",
        "    def __init__(self, hidden_size: int, num_heads: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_heads = num_heads\n",
        "        self.head_size = hidden_size // num_heads\n",
        "\n",
        "        self.WQKV = t.nn.Linear(self.hidden_size, 3 * hidden_size) # TODO: why do we use a linear layer here? aren't they matricies?\n",
        "        self.W0 = t.nn.Linear(self.hidden_size, self.hidden_size)\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        x: shape (batch, seq, hidden_size)\n",
        "\n",
        "        Return: shape (batch, seq, hidden_size)\n",
        "        '''\n",
        "        #print(\"YO?\")\n",
        "        x = x.float() # seems like it needs to be a float!\n",
        "        QKV = self.WQKV(x)\n",
        "        Q = QKV[:,:,:self.hidden_size]\n",
        "        K = QKV[:,:,self.hidden_size:self.hidden_size * 2]\n",
        "        V = QKV[:,:,self.hidden_size * 2:]\n",
        "        assert Q.shape == K.shape == V.shape == x.shape\n",
        "        return self.W0(multihead_masked_attention(Q,K,V,self.num_heads))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "nG9-RZDwOvuR"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TransformerConfig:\n",
        "    '''Constants used throughout your decoder-only transformer model.'''\n",
        "\n",
        "    num_layers: int\n",
        "    num_heads: int\n",
        "    vocab_size: int\n",
        "    hidden_size: int\n",
        "    max_seq_len: int\n",
        "    dropout: float = 0.1\n",
        "    layer_norm_epsilon: float = 1e-05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "dxznpdXeOvuS"
      },
      "outputs": [],
      "source": [
        "# from yesterday\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim: int, max_seq_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dim = embedding_dim\n",
        "        self.length = max_seq_len\n",
        "\n",
        "        # mostly copied. i understand this, just need to work on \n",
        "        # making more tensors and getting more exposure to methods of making tensors\n",
        "        def P (delta):\n",
        "            n = 10000 # hardcoded\n",
        "            d = embedding_dim\n",
        "            l = max_seq_len\n",
        "            sin_array = np.sin(delta / n ** (2 * np.arange(d//2) / d))\n",
        "            cos_array = np.cos(delta / n ** (2 * np.arange(d//2) / d))\n",
        "\n",
        "            array = np.zeros(d)\n",
        "            array[::2] = sin_array\n",
        "            array[1::2] = cos_array\n",
        "\n",
        "            return array\n",
        "\n",
        "        tokenArray = []\n",
        "        for i in range(max_seq_len):\n",
        "            tokenArray.append(P(i)) # changed from previous design\n",
        "        \n",
        "        self.multMax = t.tensor(np.array(tokenArray), dtype=t.float, device = device)\n",
        "        \n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        x: shape (batch, seq_len, embedding_dim)\n",
        "        '''\n",
        "        return x + self.multMax[:x.shape[1]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "4evwbrSDOvuT"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super().__init__()\n",
        "        self.hidden_size = config.hidden_size\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size, self.hidden_size * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden_size * 4, self.hidden_size),\n",
        "            nn.Dropout(config.dropout)\n",
        "        )\n",
        "    def forward(self, x: t.Tensor):\n",
        "        x = x.float() # seems like it needs to be a float!\n",
        "        return self.layers(x).float() # ima do the same thing again!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "O_i-QmphOvuT"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super().__init__()\n",
        "        self.attentionBlock = nn.Sequential(\n",
        "            MultiheadMaskedAttention(config.hidden_size,  config.num_heads),\n",
        "            nn.LayerNorm(config.hidden_size)\n",
        "        )\n",
        "        self.MLP = nn.Sequential(\n",
        "            MLP(config),\n",
        "            nn.LayerNorm(config.hidden_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        partOne = x + self.attentionBlock(x)\n",
        "        return (partOne + self.MLP(partOne)).float() # seems like it needs to be a float!\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "YoM0le7qOvuU"
      },
      "outputs": [],
      "source": [
        "class DecoderOnlyTransformer(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super().__init__()\n",
        "        self.tokenize = nn.Embedding(config.vocab_size, config.hidden_size).to(device)\n",
        "        self.positionize = PositionalEncoding(config.hidden_size,config.max_seq_len)\n",
        "        self.restModel = nn.Sequential(\n",
        "            nn.Dropout(config.dropout),\n",
        "            *[DecoderBlock(config) for i in range(config.num_layers)],\n",
        "            nn.LayerNorm(config.hidden_size),\n",
        "        )\n",
        "        self.unembed = self.tokenize.weight.T.to(device)\n",
        "        \n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        x = self.tokenize(x)\n",
        "        x = self.positionize(x)\n",
        "        toUnembed = self.restModel(x).to(device)\n",
        "        return toUnembed@self.unembed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E108n5oQOvuU"
      },
      "source": [
        "## Data Prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvqBu-CxOvuU"
      },
      "source": [
        "Make the dataset to parse through all of the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "x17J93OHOvuU"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "\n",
        "class CustomTextDataset(Dataset):\n",
        "    def __init__(self, words, seq_len, fractionOfWords):\n",
        "        self.fractionOfWords = fractionOfWords\n",
        "        self.words = words\n",
        "        self.setOfWords = set(words)\n",
        "        self.seq_len = seq_len\n",
        "        self.max_len = len(self.words) - (self.seq_len + 1)\n",
        "        self.vocab_size = len(self.setOfWords)\n",
        "        self.word_to_token = {word: idx for (idx, word) in enumerate(sorted(self.setOfWords))}\n",
        "        self.token_to_word = {idx: word for (idx, word) in enumerate(sorted(self.setOfWords))}\n",
        "        self.allTokens = t.tensor([self.word_to_token[word] for word in self.words],device = device)\n",
        "        \n",
        "        if (self.fractionOfWords > 0.9):\n",
        "            print(\"Probably don't do this. Errors may about\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(self.max_len * self.fractionOfWords)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.allTokens[idx:idx + self.seq_len + 1]\n",
        "        input = tokens[:-1]\n",
        "        target = tokens[1:]\n",
        "        return input, target \n",
        "\n",
        "    def getDataSize(self):\n",
        "        return self.vocab_size\n",
        "\n",
        "    def convertToTokens(self, phrase: list):\n",
        "        return t.tensor([self.word_to_token[word] for word in phrase],device = device)\n",
        "\n",
        "    def convertToText(self, tokens: t.tensor):\n",
        "        temp = []\n",
        "        for i, value in enumerate(tokens):\n",
        "            #print(value.item())\n",
        "            temp.append(self.token_to_word[value.item()])\n",
        "        return temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "nv945w7VOvuU"
      },
      "outputs": [],
      "source": [
        "file = open(\"shakespeare.txt\")\n",
        "text = file.read()\n",
        "words = re.split(r\"\\b\", text)\n",
        "\n",
        "fractionOfWords = 0.1 # what percent of the corpus to train on \n",
        "\n",
        "\n",
        "lengthOfSeq = 20\n",
        "\n",
        "shak = CustomTextDataset(words, 10, fractionOfWords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeWDlv7FOvuU"
      },
      "source": [
        "## Running this data through a transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "VdqNIkuIOvuV"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(shak, batch_size=32,shuffle=True)\n",
        "\n",
        "\n",
        "thisConfig = TransformerConfig(\n",
        "    num_layers = 4,\n",
        "    num_heads = 10,\n",
        "    vocab_size = trainloader.dataset.getDataSize(),\n",
        "    hidden_size = 100, # recall that this = num_heads * headsize\n",
        "    max_seq_len = lengthOfSeq,\n",
        "    dropout = 0.1,\n",
        "    layer_norm_epsilon=0.00001\n",
        ")\n",
        "\n",
        "myTransformer = DecoderOnlyTransformer(thisConfig).to(device)\n",
        "optimizer = t.optim.Adam(myTransformer.parameters(), lr = 1e-3)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "Tl8YEwDhOvuV"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 1\n",
        "\n",
        "losses = []\n",
        "myTransformer.train()\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    for inputs, targets in trainloader:\n",
        "        outputs = myTransformer(inputs).to(device)\n",
        "        targets = t.nn.functional.one_hot(targets, num_classes=trainloader.dataset.getDataSize()).float().to(device)\n",
        "        \n",
        "        outputs = einops.rearrange(outputs, 'batch seq vocab -> (batch seq) vocab')\n",
        "        targets = einops.rearrange(targets, 'batch seq vocab -> (batch seq) vocab')\n",
        "\n",
        "        outputs = outputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        loss = criterion(outputs,targets).to(device)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "NUjqRiN4OvuV",
        "outputId": "3b0eeb5e-f0b0-454b-d382-10d8eefed05f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f202a15cf10>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "df = pd.DataFrame(losses)\n",
        "df.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vyx4rgkOvuV",
        "outputId": "502d1db9-ebe2-4884-f4c7-5ddf0ad7f378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  111, 31102,   111, 33914,   111, 24733,   111, 24733, 34184, 24733,\n",
            "          111], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ', 'the', ' ', 'world', ' ', 'of', ' ', 'of', 'â€™', 'of', ' ']"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "# quick test:\n",
        "\n",
        "myTransformer.eval()\n",
        "\n",
        "testPhrase = [\"in\", \" \", \"the\", \" \", \"hidden\", \" \", \"field\", \" \", \"rests\", \" \", \"fifteen\"]\n",
        "input = shak.convertToTokens(list(testPhrase))\n",
        "input = input[None, :]\n",
        "tokens = myTransformer(input).argmax(dim=-1)[0]\n",
        "print(tokens)\n",
        "shak.convertToText(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "06zdsz-PTfAm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "c1829bf021947e771a2c0399247f13cc64d76e227c4c4356073fc0c03f05b7ca"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}