{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starship006/ARENA-work/blob/main/w1/w1d4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fancy_einsum einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlRgy2kjSzdd",
        "outputId": "a811e651-aa95-471d-81b0-7af4a1b75c99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fancy_einsum\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting einops\n",
            "  Downloading einops-0.5.0-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: fancy-einsum, einops\n",
            "Successfully installed einops-0.5.0 fancy-einsum-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aOsyx41fOvuN"
      },
      "outputs": [],
      "source": [
        "import torch as t\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import fancy_einsum as einsum\n",
        "import einops\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oei89mWsOvuP"
      },
      "source": [
        "# Training Shakespeare Himself"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HguafRmOvuQ"
      },
      "source": [
        "## Copy transformer code\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9pLknZ-OvuQ"
      },
      "source": [
        "Well, not copy entirely - I'm gonna put down optimizations so it can use the GPU.\n",
        "\n",
        "And I did just that. The speed improvements are MASSIVE, wow!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SMSyuB3OvuQ",
        "outputId": "36c9d02f-be9e-40b6-a6be-9101d27b6f33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
        "t.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "dARzlkbDOvuQ"
      },
      "outputs": [],
      "source": [
        "def multihead_masked_attention(Q: t.Tensor, K: t.Tensor, V: t.Tensor, num_heads: int):\n",
        "    '''\n",
        "    Implements multihead masked attention on the matrices Q, K and V.\n",
        "\n",
        "    Q: shape (batch, seq_len, nheads*headsize)\n",
        "    K: shape (batch, seq_len, nheads*headsize)\n",
        "    V: shape (batch, seq_len, nheads*headsize)\n",
        "    '''\n",
        "    \n",
        "    Q = einops.rearrange(Q, 'b s (n h) -> b n s h', n = num_heads)\n",
        "    K = einops.rearrange(K, 'b s (n h) -> b n s h', n = num_heads)\n",
        "    V = einops.rearrange(V, 'b s (n h) -> b n s h', n = num_heads)\n",
        "\n",
        "\n",
        "    scores = einsum.einsum('b n k h, b n s h -> b n s k', K, Q)\n",
        "    assert scores.shape == t.Size([Q.shape[0], num_heads,Q.shape[2], K.shape[2]])\n",
        "\n",
        "    scores = scores / np.sqrt(Q.shape[-1])\n",
        "    attention = scores + t.triu(t.ones_like(scores,device = device) * float(\"-inf\"), diagonal=1) # THIS IS STOLEN FROM JAY - testing it out\n",
        "    softed = t.softmax(attention,dim=-1)\n",
        "    result =  einsum.einsum('batch numheads seqQ seqK, batch numheads seqK headsize -> batch numheads seqQ headsize',softed, V)\n",
        "    return einops.rearrange(result, 'batch numheads seqQ headsize -> batch seqQ (numheads headsize)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "pxFIcpudOvuR"
      },
      "outputs": [],
      "source": [
        "class MultiheadMaskedAttention(nn.Module):\n",
        "    W_QKV: nn.Linear\n",
        "    W_O: nn.Linear\n",
        "\n",
        "    def __init__(self, hidden_size: int, num_heads: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_heads = num_heads\n",
        "        self.head_size = hidden_size // num_heads\n",
        "\n",
        "        self.WQKV = t.nn.Linear(self.hidden_size, 3 * hidden_size) # TODO: why do we use a linear layer here? aren't they matricies?\n",
        "        self.W0 = t.nn.Linear(self.hidden_size, self.hidden_size)\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        x: shape (batch, seq, hidden_size)\n",
        "\n",
        "        Return: shape (batch, seq, hidden_size)\n",
        "        '''\n",
        "        #print(\"YO?\")\n",
        "        x = x.float() # seems like it needs to be a float!\n",
        "        QKV = self.WQKV(x)\n",
        "        Q = QKV[:,:,:self.hidden_size]\n",
        "        K = QKV[:,:,self.hidden_size:self.hidden_size * 2]\n",
        "        V = QKV[:,:,self.hidden_size * 2:]\n",
        "        assert Q.shape == K.shape == V.shape == x.shape\n",
        "        return self.W0(multihead_masked_attention(Q,K,V,self.num_heads))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "nG9-RZDwOvuR"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TransformerConfig:\n",
        "    '''Constants used throughout your decoder-only transformer model.'''\n",
        "\n",
        "    num_layers: int\n",
        "    num_heads: int\n",
        "    vocab_size: int\n",
        "    hidden_size: int\n",
        "    max_seq_len: int\n",
        "    dropout: float = 0.1\n",
        "    layer_norm_epsilon: float = 1e-05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "dxznpdXeOvuS"
      },
      "outputs": [],
      "source": [
        "# from yesterday\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim: int, max_seq_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dim = embedding_dim\n",
        "        self.length = max_seq_len\n",
        "\n",
        "        # mostly copied. i understand this, just need to work on \n",
        "        # making more tensors and getting more exposure to methods of making tensors\n",
        "        def P (delta):\n",
        "            n = 10000 # hardcoded\n",
        "            d = embedding_dim\n",
        "            l = max_seq_len\n",
        "            sin_array = np.sin(delta / n ** (2 * np.arange(d//2) / d))\n",
        "            cos_array = np.cos(delta / n ** (2 * np.arange(d//2) / d))\n",
        "\n",
        "            array = np.zeros(d)\n",
        "            array[::2] = sin_array\n",
        "            array[1::2] = cos_array\n",
        "\n",
        "            return array\n",
        "\n",
        "        tokenArray = []\n",
        "        for i in range(max_seq_len):\n",
        "            tokenArray.append(P(i)) # changed from previous design\n",
        "        \n",
        "        self.multMax = t.tensor(np.array(tokenArray), dtype=t.float, device = device)\n",
        "        \n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        '''\n",
        "        x: shape (batch, seq_len, embedding_dim)\n",
        "        '''\n",
        "        return x + self.multMax[:x.shape[1]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "4evwbrSDOvuT"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super().__init__()\n",
        "        self.hidden_size = config.hidden_size\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size, self.hidden_size * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden_size * 4, self.hidden_size),\n",
        "            nn.Dropout(config.dropout)\n",
        "        )\n",
        "    def forward(self, x: t.Tensor):\n",
        "        x = x.float() # seems like it needs to be a float!\n",
        "        return self.layers(x).float() # ima do the same thing again!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "O_i-QmphOvuT"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super().__init__()\n",
        "        self.attentionBlock = nn.Sequential(\n",
        "            MultiheadMaskedAttention(config.hidden_size,  config.num_heads),\n",
        "            nn.LayerNorm(config.hidden_size)\n",
        "        )\n",
        "        self.MLP = nn.Sequential(\n",
        "            MLP(config),\n",
        "            nn.LayerNorm(config.hidden_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        partOne = x + self.attentionBlock(x)\n",
        "        return (partOne + self.MLP(partOne)).float() # seems like it needs to be a float!\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "YoM0le7qOvuU"
      },
      "outputs": [],
      "source": [
        "class DecoderOnlyTransformer(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super().__init__()\n",
        "        self.tokenize = nn.Embedding(config.vocab_size, config.hidden_size).to(device)\n",
        "        self.positionize = PositionalEncoding(config.hidden_size,config.max_seq_len)\n",
        "        self.restModel = nn.Sequential(\n",
        "            nn.Dropout(config.dropout),\n",
        "            *[DecoderBlock(config) for i in range(config.num_layers)],\n",
        "            nn.LayerNorm(config.hidden_size),\n",
        "        )\n",
        "        self.unembed = self.tokenize.weight.T.to(device)\n",
        "        \n",
        "    def forward(self, x: t.Tensor) -> t.Tensor:\n",
        "        x = self.tokenize(x)\n",
        "        x = self.positionize(x)\n",
        "        toUnembed = self.restModel(x).to(device)\n",
        "        return toUnembed@self.unembed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E108n5oQOvuU"
      },
      "source": [
        "## Data Prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvqBu-CxOvuU"
      },
      "source": [
        "Make the dataset to parse through all of the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "x17J93OHOvuU"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "\n",
        "class CustomTextDataset(Dataset):\n",
        "    def __init__(self, words, seq_len, fractionOfWords):\n",
        "        self.fractionOfWords = fractionOfWords\n",
        "        self.words = words\n",
        "        self.setOfWords = set(words)\n",
        "        self.seq_len = seq_len\n",
        "        self.max_len = len(self.words) - (self.seq_len + 1)\n",
        "        self.vocab_size = len(self.setOfWords)\n",
        "        self.word_to_token = {word: idx for (idx, word) in enumerate(sorted(self.setOfWords))}\n",
        "        self.token_to_word = {idx: word for (idx, word) in enumerate(sorted(self.setOfWords))}\n",
        "        self.allTokens = t.tensor([self.word_to_token[word] for word in self.words],device = device)\n",
        "        \n",
        "        if (self.fractionOfWords > 0.9):\n",
        "            print(\"Probably don't do this. Errors may about\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(self.max_len * self.fractionOfWords)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.allTokens[idx:idx + self.seq_len + 1]\n",
        "        input = tokens[:-1]\n",
        "        target = tokens[1:]\n",
        "        return input, target \n",
        "\n",
        "    def getDataSize(self):\n",
        "        return self.vocab_size\n",
        "\n",
        "    def convertToTokens(self, phrase: list) -> t.tensor:\n",
        "        return t.tensor([self.word_to_token[word] for word in phrase],device = device)\n",
        "\n",
        "    def convertStringToTokenList(self, phrase: str) -> list:\n",
        "        words = re.split(r\"\\b\", phrase)\n",
        "        return [self.word_to_token[word] for word in words]\n",
        "\n",
        "    def convertToText(self, tokens: t.tensor):\n",
        "        temp = []\n",
        "        for i, value in enumerate(tokens):\n",
        "            #print(value.item())\n",
        "            temp.append(self.token_to_word[value.item()])\n",
        "        return temp\n",
        "\n",
        "    def decodeList(self, words: list):\n",
        "        temp = []\n",
        "        for value in words:\n",
        "            temp.append(self.token_to_word[value])\n",
        "        return temp\n",
        "        \n",
        "    def listToString(self, words: list) -> str:\n",
        "        temp = \"\"\n",
        "        for word in words:\n",
        "            temp = temp + word\n",
        "        return temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "nv945w7VOvuU"
      },
      "outputs": [],
      "source": [
        "file = open(\"shakespeare.txt\")\n",
        "text = file.read()\n",
        "words = re.split(r\"\\b\", text)\n",
        "\n",
        "fractionOfWords = 0.1 # what percent of the corpus to train on \n",
        "\n",
        "\n",
        "lengthOfSeq = 100\n",
        "\n",
        "shak = CustomTextDataset(words, lengthOfSeq, fractionOfWords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeWDlv7FOvuU"
      },
      "source": [
        "## Running this data through a transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "VdqNIkuIOvuV"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(shak, batch_size=32,shuffle=True)\n",
        "\n",
        "# this specific one trained for 24 minutes and 9 seconds on colab GPU\n",
        "\n",
        "thisConfig = TransformerConfig(\n",
        "    num_layers = 4, # 6 layers in the Attention paper\n",
        "    num_heads = 4, # 8 heads in Attention paper\n",
        "    vocab_size = trainloader.dataset.getDataSize(), # 37000 tokens in Attention paper (?)\n",
        "    hidden_size = 512, # recall that this = num_heads * headsize | 512 is the embedding dim used in Attention paper\n",
        "    max_seq_len = lengthOfSeq, \n",
        "    dropout = 0.1, # same as Attention paper\n",
        "    layer_norm_epsilon=0.00001\n",
        ")\n",
        "\n",
        "myTransformer = DecoderOnlyTransformer(thisConfig).to(device)\n",
        "optimizer = t.optim.Adam(myTransformer.parameters(), lr = 1e-3)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "Tl8YEwDhOvuV"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 1\n",
        "\n",
        "losses = []\n",
        "myTransformer.train()\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    for inputs, targets in trainloader:\n",
        "        outputs = myTransformer(inputs).to(device)\n",
        "        targets = t.nn.functional.one_hot(targets, num_classes=trainloader.dataset.getDataSize()).float().to(device)\n",
        "        \n",
        "        outputs = einops.rearrange(outputs, 'batch seq vocab -> (batch seq) vocab')\n",
        "        targets = einops.rearrange(targets, 'batch seq vocab -> (batch seq) vocab')\n",
        "\n",
        "        outputs = outputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        loss = criterion(outputs,targets).to(device)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "NUjqRiN4OvuV",
        "outputId": "82e19786-1fac-421e-e75c-4ea4081eb059"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f35f5b835d0>"
            ]
          },
          "metadata": {},
          "execution_count": 142
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "df = pd.DataFrame(losses)\n",
        "df.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vyx4rgkOvuV",
        "outputId": "879c83db-4f97-45a7-cd4c-132df03c8182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  111, 22082,   111, 24741,   111, 31376,   111, 20247,   111, 24082,\n",
            "          405,  9859,   111], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " 'it',\n",
              " ' ',\n",
              " 'offended',\n",
              " ' ',\n",
              " 'to',\n",
              " ' ',\n",
              " 'govern',\n",
              " ' ',\n",
              " 'mother',\n",
              " ',\\n',\n",
              " 'The',\n",
              " ' ']"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "# quick test - use sample method to actually use the transformer: \n",
        "\n",
        "myTransformer.eval()\n",
        "\n",
        "testPhrase = [\"Be\", \" \", \"not\", \" \", \"afraid\", \" \", \"to\", \" \", \"the\", \" \", \"Florentine\", \"\\n\",\n",
        "              \"And\"]\n",
        "input = shak.convertToTokens(testPhrase)\n",
        "input = input[None, :]\n",
        "tokens = myTransformer(input).argmax(dim=-1)[0]\n",
        "print(tokens)\n",
        "shak.convertToText(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling"
      ],
      "metadata": {
        "id": "CSwuSOXhVi1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_sampling_methods(input_ids: t.Tensor, logits: t.Tensor, temperature=1.0, freq_penalty=0.0, top_k=0, top_p=0.0) -> int:\n",
        "  # returns a next token based on provided samplingm ethod\n",
        "  # thanks jacob for the this method\n",
        "  assert input_ids.ndim == 1, \"input_ids should be a 1D sequence of token ids\"\n",
        "  assert temperature >= 0, \"Temperature should be non-negative\"\n",
        "  assert 0 <= top_p <= 1.0, \"Top-p must be a probability\"\n",
        "  assert 0 <= top_k, \"Top-k must be non-negative\"\n",
        "  assert not (top_p != 0 and top_k != 0), \"At most one of top-p and top-k supported\"\n",
        "\n",
        "  if temperature == 0:\n",
        "    return greedy_search(logits)\n",
        "  \n",
        "  return sample_basic(logits)\n",
        "\n",
        "\n",
        "def sample_token(\n",
        "    model,\n",
        "    encodeMethod,\n",
        "    decodeMethod,\n",
        "    initial_text: str,\n",
        "    max_tokens_generated = 40,\n",
        "    **kwargs) -> str:\n",
        "    # samples tokens until model outputs eos_token_id or token limit reached\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "    model.eval()\n",
        "    input_ids: list = encodeMethod(initial_text)\n",
        "    generated_ids = []\n",
        "    device = next(model.parameters()).device #what is next doing here?\n",
        "\n",
        "    tokens_to_generate = max_tokens_generated - len(input_ids)\n",
        "    for _ in range(tokens_to_generate):\n",
        "        #print(input_ids + generated_ids)\n",
        "        new_input_ids = t.tensor(input_ids + generated_ids, dtype=t.int64, device=device)\n",
        "        #print(new_input_ids.unsqueeze(0).shape)\n",
        "        logits = model(new_input_ids.unsqueeze(0))[0, -1]\n",
        "        #print(logits.shape)\n",
        "        new_token = apply_sampling_methods(new_input_ids, logits, **kwargs)\n",
        "        generated_ids.append(new_token)\n",
        "\n",
        "      \n",
        "    return decodeMethod(input_ids + generated_ids)\n",
        "\n",
        "\n",
        "# quick test:\n",
        "\n",
        "myTransformer.eval()\n",
        "\n",
        "testPhrase = [\"Be\", \" \", \"not\", \" \", \"afraid\", \" \", \"to\", \" \", \"the\", \" \", \"Florentine\", \"\\n\",\n",
        "              \"And\"]\n",
        "input = shak.convertToTokens(testPhrase)\n",
        "type(input)\n",
        "\n",
        "\n",
        "print(shak.listToString(sample_token(myTransformer,shak.convertStringToTokenList,shak.decodeList,\n",
        "                                     \"The world burns in\", 100)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkE5o5i-VlVK",
        "outputId": "1cb4009d-c6eb-4c48-c456-8a225962e591"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The world burns in, brotherly is never shaken;\n",
            "It is the brain and her for every hour,\n",
            "Reserve them for my love, not for their rhyme,\n",
            "Exceeded by the height of happier men.\n",
            "O then vouchsafe me but this loving thought,\n",
            "’Had my friend’s Muse grown with this \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_search(logits):\n",
        "    '''\n",
        "    returns the most likely next token, BUT THE TIEBREAKER IS INCORRECT!\n",
        "    i got lazy - it *is* deterministic, but it just doesn't necessarily\n",
        "    choose the smallest word out of the tie. perhaps treat it as a symbol\n",
        "    of my ingenuity?\n",
        "    '''\n",
        "    return logits.argmax(dim=-1).item()"
      ],
      "metadata": {
        "id": "McngECeVWCl-"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_basic(logits):\n",
        "    '''\n",
        "    samples from the distributions, possibly with temp and freq changes applied\n",
        "\n",
        "    logits: shape (vocab_size, ) - unnormalized log-probabilities\n",
        "\n",
        "    return: a sampled token\n",
        "    '''\n",
        "    probs = t.distributions.categorical.Categorical(logits=logits)\n",
        "    return probs.sample().item()\n",
        "\n",
        "N = 20000\n",
        "probs = t.linspace(0, 0.4, 5)\n",
        "unnormalized_logits = probs.log() + 1.2345\n",
        "samples = t.tensor([sample_basic(unnormalized_logits) for _ in range(N)])\n",
        "counts = t.bincount(samples, minlength=len(probs)) / N\n",
        "print(\"Checking empirical frequencies (try to increase N if this test fails): \", counts)\n",
        "t.testing.assert_close(counts, probs, atol=0.01, rtol=0)\n",
        "print(\"Tests passed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCZKbbAkltBf",
        "outputId": "2ce05748-87c4-4b11-9592-0bf8009be3d6"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking empirical frequencies (try to increase N if this test fails):  tensor([0.0000, 0.1006, 0.2010, 0.2980, 0.4004])\n",
            "Tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model for future use\n",
        "(This was over 20 minutes of GPU computation. Not too shabby!)"
      ],
      "metadata": {
        "id": "FSfPwNmmmY32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.save(myTransformer.state_dict(), \"toInfer.pt\")"
      ],
      "metadata": {
        "id": "CBK0fyujcfIr"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newModel = DecoderOnlyTransformer(thisConfig).to(device)\n",
        "newModel.load_state_dict(t.load(\"toInfer.pt\"))\n",
        "newModel.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa-H0lEplC5j",
        "outputId": "d00d362d-c8e6-4e99-9baa-426a430a1c88"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecoderOnlyTransformer(\n",
              "  (tokenize): Embedding(34234, 512)\n",
              "  (positionize): PositionalEncoding()\n",
              "  (restModel): Sequential(\n",
              "    (0): Dropout(p=0.1, inplace=False)\n",
              "    (1): DecoderBlock(\n",
              "      (attentionBlock): Sequential(\n",
              "        (0): MultiheadMaskedAttention(\n",
              "          (WQKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (W0): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (MLP): Sequential(\n",
              "        (0): MLP(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (1): GELU(approximate=none)\n",
              "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (3): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (2): DecoderBlock(\n",
              "      (attentionBlock): Sequential(\n",
              "        (0): MultiheadMaskedAttention(\n",
              "          (WQKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (W0): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (MLP): Sequential(\n",
              "        (0): MLP(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (1): GELU(approximate=none)\n",
              "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (3): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (3): DecoderBlock(\n",
              "      (attentionBlock): Sequential(\n",
              "        (0): MultiheadMaskedAttention(\n",
              "          (WQKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (W0): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (MLP): Sequential(\n",
              "        (0): MLP(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (1): GELU(approximate=none)\n",
              "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (3): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (4): DecoderBlock(\n",
              "      (attentionBlock): Sequential(\n",
              "        (0): MultiheadMaskedAttention(\n",
              "          (WQKV): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (W0): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (MLP): Sequential(\n",
              "        (0): MLP(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (1): GELU(approximate=none)\n",
              "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (3): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YoCPqZUilokP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "c1829bf021947e771a2c0399247f13cc64d76e227c4c4356073fc0c03f05b7ca"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}