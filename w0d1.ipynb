{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from typing import Optional, Callable\n",
    "import ipywidgets as wg\n",
    "from fancy_einsum import einsum\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Fourier Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(forgot that the outer product existed. whoops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12. +0.j       , -1.5+0.8660254j, -1.5-0.8660254j])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def DFT_1d(arr : np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns the Discrete Fourier Transform of the array 'arr'\n",
    "    \"\"\"\n",
    "    leftArray =  np.fromfunction(lambda x, y: np.power(np.power(np.e,-2 * np.pi * 1j / len(arr)),x * y), (arr.shape[0], arr.shape[0]), dtype=float)\n",
    "    # print(leftArray.shape)\n",
    "    # print(arr.shape)\n",
    "    return leftArray@arr\n",
    "\n",
    "DFT_1d(np.array([3,4,5]))\n",
    "# expected: [12. +0.j        -1.5+0.8660254j -1.5-0.8660254j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Discrete Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFT_1d(arr: np.ndarray, inverse: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns the DFT of the array `arr`, with an optional `inverse` argument.\n",
    "    \"\"\"\n",
    "    if inverse:\n",
    "        leftArray =  np.fromfunction(lambda x, y: np.power(np.power(np.e,2 * np.pi * 1j / len(arr)),x * y), (arr.shape[0], arr.shape[0]), dtype=float)\n",
    "        return leftArray@arr / len(arr)\n",
    "    else:\n",
    "        leftArray =  np.fromfunction(lambda x, y: np.power(np.power(np.e,-2 * np.pi * 1j / len(arr)),x * y), (arr.shape[0], arr.shape[0]), dtype=float)\n",
    "        return leftArray@arr\n",
    "    \n",
    "\n",
    "utils.test_DFT_func(DFT_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A sample test function \n",
    "\n",
    "(or, more accurately, lines of code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2 - 1j, -1j, -1 + 2j])\n",
    "expectedTransform = (2, -2 - 2j, -2j, 4 + 4j)\n",
    "gotTransform = DFT_1d(x)\n",
    "np.testing.assert_allclose(expectedTransform,gotTransform, atol=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Fourier Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_function(func: Callable, x0: float, x1: float, n_samples: int = 1000):\n",
    "    \"\"\"\n",
    "    Calculates the approximation of the Riemann integral of the function `func`, \n",
    "    between the limits x0 and x1.\n",
    "\n",
    "    You should use the Left Rectangular Approximation Method (LRAM).\n",
    "    \"\"\"\n",
    "\n",
    "    x_width = (x1 - x0) / n_samples\n",
    "    total = 0\n",
    "    for i in range(n_samples):\n",
    "        total += func(i * x_width + x0) * x_width\n",
    "\n",
    "    return total\n",
    "\n",
    "utils.test_integrate_function(integrate_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_product(func1: Callable, func2: Callable, x0: float, x1: float):\n",
    "    \"\"\"\n",
    "    Computes the integral of the function x -> func1(x) * func2(x).\n",
    "    \"\"\"\n",
    "\n",
    "    def product(x):\n",
    "        return func1(x) * func2(x)\n",
    "\n",
    "    return integrate_function(product,x0,x1)\n",
    "\n",
    "utils.test_integrate_product(integrate_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_interactive_fourier_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39mreturn\u001b[39;00m ((a0, A_n, B_n), newFunction)\n\u001b[1;32m     33\u001b[0m step_func \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39m1\u001b[39m \u001b[39m*\u001b[39m (x \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m create_interactive_fourier_graph(calculate_fourier_series, func \u001b[39m=\u001b[39m step_func)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_interactive_fourier_graph' is not defined"
     ]
    }
   ],
   "source": [
    "def calculate_fourier_series(func: Callable, max_freq: int = 50):\n",
    "    \"\"\"\n",
    "    Calculates the fourier coefficients of a function, \n",
    "    assumed periodic between [-pi, pi].\n",
    "\n",
    "    Your function should return ((a_0, A_n, B_n), func_approx), where:\n",
    "        a_0 is a float\n",
    "        A_n, B_n are lists of floats, with n going up to `max_freq`\n",
    "        func_approx is the fourier approximation, as described above\n",
    "    \"\"\"\n",
    "    a0 = 1 / np.pi * integrate_function(func,-1 * np.pi, np.pi)\n",
    "    A_n = []\n",
    "    B_n = []\n",
    "\n",
    "    def modifiedCos(x, i):\n",
    "        return np.cos(x * i)\n",
    "\n",
    "    for i in range(1,50):\n",
    "        print(i)\n",
    "        newFunc = lambda x: np.cos(i*x)\n",
    "        A_n.append(1 / np.pi * integrate_product(func, newFunc, -1 * np.pi, np.pi))\n",
    "        newFunc = lambda y: np.sin(i*x)\n",
    "        B_n.append(1 / np.pi * integrate_product(func, newFunc, -1 * np.pi, np.pi))\n",
    "    \n",
    "    def newFunction(x):\n",
    "        output = a0 / 2\n",
    "        for i in range(1,50):\n",
    "            output += A_n[i] * np.cos( (i-0) * x)\n",
    "            output += B_n[i] * np.sin( (i-0) * x)\n",
    "        return output\n",
    "    return ((a0, A_n, B_n), newFunction)\n",
    "\n",
    "step_func = lambda x: 1 * (x > 0)\n",
    "create_interactive_fourier_graph(calculate_fourier_series, func = step_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ipywidgets._version' from '/Users/codyrushing/mambaforge/envs/ARENAenv/lib/python3.9/site-packages/ipywidgets/_version.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wg._version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*okay, this one was rough. I spent over an hour on this section jsut trying to work it out, and I enventually had to look up the answers for some guidance. I have some of the high-level ideas down, but there are some small parts to this that I need to flush out.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 21682.73\n",
      "loss = 14546.42\n",
      "loss = 9762.67\n",
      "loss = 6555.61\n",
      "loss = 4405.31\n",
      "loss = 2963.34\n",
      "loss = 1996.21\n",
      "loss = 1347.40\n",
      "loss = 912.02\n",
      "loss = 619.77\n",
      "loss = 423.52\n",
      "loss = 291.67\n",
      "loss = 203.03\n",
      "loss = 143.41\n",
      "loss = 103.26\n",
      "loss = 76.20\n",
      "loss = 57.94\n",
      "loss = 45.60\n",
      "loss = 37.24\n",
      "loss = 31.57\n",
      "loss = 27.71\n",
      "loss = 25.08\n",
      "loss = 23.27\n",
      "loss = 22.03\n",
      "loss = 21.18\n",
      "loss = 20.58\n",
      "loss = 20.16\n",
      "loss = 19.87\n",
      "loss = 19.66\n",
      "loss = 19.51\n",
      "loss = 19.40\n",
      "loss = 19.32\n",
      "loss = 19.27\n",
      "loss = 19.22\n",
      "loss = 19.19\n",
      "loss = 19.17\n",
      "loss = 19.15\n",
      "loss = 19.13\n",
      "loss = 19.12\n",
      "loss = 19.11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4371527cc146debe580de2c3eb6c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Number of steps: '), IntSlider(value=0, max=3900, step=100)), layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "NUM_FREQUENCIES = 10\n",
    "TARGET_FUNC = lambda x: 1 * (x > 1)\n",
    "TOTAL_STEPS = 4000\n",
    "LEARNING_RATE = 1e-6\n",
    "\n",
    "x = np.linspace(-np.pi, np.pi, 2000)\n",
    "y = TARGET_FUNC(x)\n",
    "\n",
    "x_cos = np.array([np.cos(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_sin = np.array([np.sin(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "\n",
    "\n",
    "a_0 = np.random.randn()\n",
    "A_n = np.random.randn(NUM_FREQUENCIES)\n",
    "B_n = np.random.randn(NUM_FREQUENCIES)\n",
    "\n",
    "y_pred_list = []\n",
    "coeffs_list = []\n",
    "\n",
    "for step in range(TOTAL_STEPS):\n",
    "\n",
    "    y_pred = 0.5 * a_0 + x_cos.T @ A_n + x_sin.T @ B_n\n",
    "\n",
    "    lossArray:np.ndarray = (y_pred - y)\n",
    "    loss = np.square(lossArray).sum()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f\"loss = {loss:.2f}\")\n",
    "        coeffs_list.append([a_0, A_n.copy(), B_n.copy()])\n",
    "        y_pred_list.append(y_pred)\n",
    "\n",
    "    dL_dy = 2.0 * (y_pred - y)\n",
    "    dL_da0 = 0.5 * dL_dy.sum()\n",
    "    dL_da = x_cos @ dL_dy\n",
    "    dL_db = x_sin @ dL_dy\n",
    "    # pdb.set_trace() \n",
    "\n",
    "\n",
    "    a_0 -= LEARNING_RATE * dL_da0 \n",
    "    A_n -= LEARNING_RATE * dL_da\n",
    "    B_n -= LEARNING_RATE * dL_db\n",
    "    #pdb.set_trace() \n",
    "\n",
    "\n",
    "utils.visualise_fourier_coeff_convergence(x, y, y_pred_list, coeffs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch and Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8131e+20, 1.7566e+25, 1.7748e+28, 0.0000e+00, 0.0000e+00]) tensor([5.]) tensor([5.])\n"
     ]
    }
   ],
   "source": [
    "# \"the constructor way is fraught with peril\"\n",
    "\n",
    "import torch\n",
    "x = torch.arange(5)\n",
    "y1 = torch.Tensor(x.shape)\n",
    "y2 = torch.Tensor(tuple(x.shape))\n",
    "y3 = torch.Tensor(list(x.shape))\n",
    "print(y1, y2, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor([1,2,3,4]).mean() will not run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1703.44\n",
      "loss = 1181.91\n",
      "loss = 829.02\n",
      "loss = 589.76\n",
      "loss = 427.15\n",
      "loss = 316.31\n",
      "loss = 240.51\n",
      "loss = 188.47\n",
      "loss = 152.58\n",
      "loss = 127.69\n",
      "loss = 110.32\n",
      "loss = 98.13\n",
      "loss = 89.50\n",
      "loss = 83.34\n",
      "loss = 78.91\n",
      "loss = 75.68\n",
      "loss = 73.32\n",
      "loss = 71.56\n",
      "loss = 70.25\n",
      "loss = 69.26\n",
      "loss = 68.50\n",
      "loss = 67.92\n",
      "loss = 67.46\n",
      "loss = 67.11\n",
      "loss = 66.83\n",
      "loss = 66.61\n",
      "loss = 66.43\n",
      "loss = 66.29\n",
      "loss = 66.18\n",
      "loss = 66.09\n",
      "loss = 66.02\n",
      "loss = 65.96\n",
      "loss = 65.91\n",
      "loss = 65.87\n",
      "loss = 65.84\n",
      "loss = 65.81\n",
      "loss = 65.79\n",
      "loss = 65.77\n",
      "loss = 65.76\n",
      "loss = 65.75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8741c5bfc2894955a5d3fb3139f83ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Number of steps: '), IntSlider(value=0, max=3900, step=100)), layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bdb import set_trace\n",
    "\n",
    "\n",
    "NUM_FREQUENCIES = 2\n",
    "TARGET_FUNC = lambda x: 1 * (x > 1)\n",
    "TOTAL_STEPS = 4000\n",
    "LEARNING_RATE = 1e-6\n",
    "\n",
    "x = t.linspace(-t.pi, t.pi, 2000)\n",
    "y = TARGET_FUNC(x)\n",
    "\n",
    "x_cos = t.stack([t.cos(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_sin = t.stack([t.sin(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "\n",
    "a_0 = t.rand(1)\n",
    "A_n = t.rand(NUM_FREQUENCIES)\n",
    "B_n = t.rand(NUM_FREQUENCIES)\n",
    "\n",
    "y_pred_list = []\n",
    "coeffs_list = []\n",
    "\n",
    "for step in range(TOTAL_STEPS):\n",
    "\n",
    "    y_pred = 0.5 * a_0 + x_cos.T @ A_n + x_sin.T @ B_n\n",
    "\n",
    "    lossArray = (y_pred - y)\n",
    "    loss = t.square(lossArray).sum()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f\"loss = {loss:.2f}\")\n",
    "        # don't quite get where the to(\"cpu\") in the solution comes from, but here we go\n",
    "        coeffs_list.append([a_0.item(), A_n.to(\"cpu\").numpy().copy(), B_n.to(\"cpu\").numpy().copy()])\n",
    "        y_pred_list.append(y_pred.numpy().copy())\n",
    "\n",
    "    dL_dy = 2.0 * (y_pred - y)\n",
    "    dL_da0 = 0.5 * dL_dy.sum()\n",
    "    dL_da = x_cos @ dL_dy\n",
    "    dL_db = x_sin @ dL_dy\n",
    "\n",
    "\n",
    "    a_0 -= LEARNING_RATE * dL_da0 \n",
    "    A_n -= LEARNING_RATE * dL_da\n",
    "    B_n -= LEARNING_RATE * dL_db\n",
    "    #pdb.set_trace() \n",
    "\n",
    "\n",
    "utils.visualise_fourier_coeff_convergence(x.numpy().copy(), y.numpy().copy(), y_pred_list, coeffs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = t.tensor(2, dtype = torch.float, requires_grad=True)\n",
    "Q = 3 * a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1499.13\n",
      "loss = 1026.22\n",
      "loss = 709.34\n",
      "loss = 497.01\n",
      "loss = 354.72\n",
      "loss = 259.38\n",
      "loss = 195.49\n",
      "loss = 152.68\n",
      "loss = 123.99\n",
      "loss = 104.76\n",
      "loss = 91.88\n",
      "loss = 83.25\n",
      "loss = 77.46\n",
      "loss = 73.58\n",
      "loss = 70.98\n",
      "loss = 69.24\n",
      "loss = 68.07\n",
      "loss = 67.29\n",
      "loss = 66.77\n",
      "loss = 66.41\n",
      "loss = 66.18\n",
      "loss = 66.02\n",
      "loss = 65.91\n",
      "loss = 65.84\n",
      "loss = 65.79\n",
      "loss = 65.76\n",
      "loss = 65.74\n",
      "loss = 65.73\n",
      "loss = 65.72\n",
      "loss = 65.71\n",
      "loss = 65.71\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e08adb887174ea28d610e9ef18dd8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Number of steps: '), IntSlider(value=0, max=3900, step=100)), layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bdb import set_trace\n",
    "from pydoc import doc\n",
    "\n",
    "\n",
    "NUM_FREQUENCIES = 2\n",
    "TARGET_FUNC = lambda x: 1 * (x > 1)\n",
    "TOTAL_STEPS = 4000\n",
    "LEARNING_RATE = 1e-6\n",
    "\n",
    "x = t.linspace(-t.pi, t.pi, 2000)\n",
    "y = TARGET_FUNC(x)\n",
    "\n",
    "x_cos = t.stack([t.cos(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_sin = t.stack([t.sin(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "\n",
    "a_0 = t.rand(1, dtype=torch.float, requires_grad=True)\n",
    "A_n = t.rand(NUM_FREQUENCIES, dtype=torch.float, requires_grad=True)\n",
    "B_n = t.rand(NUM_FREQUENCIES, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "y_pred_list = []\n",
    "coeffs_list = []\n",
    "\n",
    "for step in range(TOTAL_STEPS):\n",
    "\n",
    "    y_pred = 0.5 * a_0 + x_cos.T @ A_n + x_sin.T @ B_n\n",
    "\n",
    "    lossArray = (y_pred - y)\n",
    "    loss = t.square(lossArray).sum()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f\"loss = {loss:.2f}\")\n",
    "        # don't quite get where the to(\"cpu\") in the solution comes from, but here we go\n",
    "        coeffs_list.append([a_0.item(), A_n.detach().to(\"cpu\").numpy().copy(), B_n.detach().to(\"cpu\").numpy().copy()])\n",
    "        y_pred_list.append(y_pred.detach().numpy().copy())\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        a_0 -= LEARNING_RATE * a_0.grad # compiler is throwing an error here. dunno why!\n",
    "        A_n -= LEARNING_RATE * A_n.grad\n",
    "        B_n -= LEARNING_RATE * B_n.grad\n",
    "        a_0.grad = None\n",
    "        A_n.grad = None\n",
    "        B_n.grad = None\n",
    "        \n",
    "    #pdb.set_trace() \n",
    "\n",
    "\n",
    "utils.visualise_fourier_coeff_convergence(x.numpy().copy(), y.numpy().copy(), y_pred_list, coeffs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1931.37\n",
      "loss = 1221.65\n",
      "loss = 798.00\n",
      "loss = 537.42\n",
      "loss = 373.26\n",
      "loss = 267.96\n",
      "loss = 199.50\n",
      "loss = 154.58\n",
      "loss = 124.91\n",
      "loss = 105.21\n",
      "loss = 92.10\n",
      "loss = 83.36\n",
      "loss = 77.52\n",
      "loss = 73.61\n",
      "loss = 71.00\n",
      "loss = 69.25\n",
      "loss = 68.07\n",
      "loss = 67.29\n",
      "loss = 66.76\n",
      "loss = 66.41\n",
      "loss = 66.17\n",
      "loss = 66.02\n",
      "loss = 65.91\n",
      "loss = 65.84\n",
      "loss = 65.79\n",
      "loss = 65.76\n",
      "loss = 65.74\n",
      "loss = 65.72\n",
      "loss = 65.72\n",
      "loss = 65.71\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0805f35880ec4854adac4649d2ac9f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Number of steps: '), IntSlider(value=0, max=3900, step=100)), layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pdb import set_trace\n",
    "\n",
    "\n",
    "NUM_FREQUENCIES = 2\n",
    "TARGET_FUNC = lambda x: 1 * (x > 1)\n",
    "TOTAL_STEPS = 4000\n",
    "LEARNING_RATE = 1e-6\n",
    "\n",
    "x = t.linspace(-t.pi, t.pi, 2000, dtype = t.float)\n",
    "y = TARGET_FUNC(x)\n",
    "\n",
    "x_cos = t.stack([t.cos(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_sin = t.stack([t.sin(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "\n",
    "x_input = t.concat([x_cos, x_sin], dim = 0).T\n",
    "model = torch.nn.Sequential(torch.nn.Linear(2 * NUM_FREQUENCIES, 1), torch.nn.Flatten(0, 1))\n",
    "\n",
    "# a_0 = t.rand(1, dtype=torch.float, requires_grad=True)\n",
    "# A_n = t.rand(NUM_FREQUENCIES, dtype=torch.float, requires_grad=True)\n",
    "# B_n = t.rand(NUM_FREQUENCIES, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "y_pred_list = []\n",
    "coeffs_list = []\n",
    "\n",
    "for step in range(TOTAL_STEPS):\n",
    "\n",
    "    y_pred = model(x_input)\n",
    "\n",
    "    lossArray = (y_pred - y)\n",
    "    loss = t.square(lossArray).sum()\n",
    "\n",
    "    # copied :)\n",
    "    if step % 100 == 0:\n",
    "        print(f\"{loss = :.2f}\")\n",
    "        A_n = list(model.parameters())[0].detach().numpy()[:3].squeeze()\n",
    "        B_n = list(model.parameters())[0].detach().numpy()[:6].squeeze()\n",
    "        a_0 = list(model.parameters())[1].item()\n",
    "        y_pred_list.append(y_pred.cpu().detach().numpy())\n",
    "        coeffs_list.append([a_0, A_n.copy(), B_n.copy()])\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= LEARNING_RATE * param.grad\n",
    "    model.zero_grad()\n",
    "    #pdb.set_trace() \n",
    "\n",
    "\n",
    "utils.visualise_fourier_coeff_convergence(x.numpy().copy(), y.numpy().copy(), y_pred_list, coeffs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 889.94\n",
      "loss = 609.66\n",
      "loss = 429.69\n",
      "loss = 307.42\n",
      "loss = 221.89\n",
      "loss = 163.29\n",
      "loss = 124.55\n",
      "loss = 99.91\n",
      "loss = 84.84\n",
      "loss = 75.99\n",
      "loss = 71.00\n",
      "loss = 68.31\n",
      "loss = 66.92\n",
      "loss = 66.24\n",
      "loss = 65.93\n",
      "loss = 65.79\n",
      "loss = 65.73\n",
      "loss = 65.71\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n",
      "loss = 65.70\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87dba7df1364899bd5c4c3196fe0d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Number of steps: '), IntSlider(value=0, max=3900, step=100)), layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pdb import set_trace\n",
    "\n",
    "\n",
    "NUM_FREQUENCIES = 2\n",
    "TARGET_FUNC = lambda x: 1 * (x > 1)\n",
    "TOTAL_STEPS = 4000\n",
    "LEARNING_RATE = 1e-6\n",
    "\n",
    "x = t.linspace(-t.pi, t.pi, 2000, dtype = t.float)\n",
    "y = TARGET_FUNC(x)\n",
    "\n",
    "x_cos = t.stack([t.cos(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "x_sin = t.stack([t.sin(n*x) for n in range(1, NUM_FREQUENCIES+1)])\n",
    "\n",
    "x_input = t.concat([x_cos, x_sin], dim = 0).T\n",
    "model = torch.nn.Sequential(torch.nn.Linear(2 * NUM_FREQUENCIES, 1), torch.nn.Flatten(0, 1))\n",
    "optimizer = t.optim.Adam(model.parameters(), lr=0.001)\n",
    "# a_0 = t.rand(1, dtype=torch.float, requires_grad=True)\n",
    "# A_n = t.rand(NUM_FREQUENCIES, dtype=torch.float, requires_grad=True)\n",
    "# B_n = t.rand(NUM_FREQUENCIES, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "y_pred_list = []\n",
    "coeffs_list = []\n",
    "\n",
    "for step in range(TOTAL_STEPS):\n",
    "\n",
    "    y_pred = model(x_input)\n",
    "\n",
    "    lossArray = (y_pred - y)\n",
    "    loss = t.square(lossArray).sum()\n",
    "\n",
    "    # copied :)\n",
    "    if step % 100 == 0:\n",
    "        print(f\"{loss = :.2f}\")\n",
    "        A_n = list(model.parameters())[0].detach().numpy()[:3].squeeze()\n",
    "        B_n = list(model.parameters())[0].detach().numpy()[:6].squeeze()\n",
    "        a_0 = list(model.parameters())[1].item()\n",
    "        y_pred_list.append(y_pred.cpu().detach().numpy())\n",
    "        coeffs_list.append([a_0, A_n.copy(), B_n.copy()])\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    #pdb.set_trace() \n",
    "\n",
    "\n",
    "utils.visualise_fourier_coeff_convergence(x.numpy().copy(), y.numpy().copy(), y_pred_list, coeffs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ARENAenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1829bf021947e771a2c0399247f13cc64d76e227c4c4356073fc0c03f05b7ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
